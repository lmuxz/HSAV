{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "sys.path.append(\"../model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "from io_utils import load_dataset, load_model, model_log\n",
    "from metric import performance_logloss, performance_pr_auc\n",
    "\n",
    "from train_utils import sample_validation_data\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "task = \"kaggle\"\n",
    "model_type = \"nn\"\n",
    "\n",
    "num_dim = 43\n",
    "period = [0, 1, 2]\n",
    "cate_index = 8\n",
    "\n",
    "epoch = 25\n",
    "batch_size = 512\n",
    "n_label = 200\n",
    "\n",
    "version = \"exp_finetune\"\n",
    "\n",
    "\n",
    "source_version = \"uni\"\n",
    "data_type = \"uni\"\n",
    "source_domain = \"source\"\n",
    "target_domain = \"target\"\n",
    "\n",
    "\n",
    "for seed in range(10):\n",
    "    for p in period:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        print(\"Period:\", p, seed, flush=True)\n",
    "        \n",
    "        # load source and target data\n",
    "        source_train, source_train_label, source_test, source_test_label = load_dataset(\"../data/\", \n",
    "                                                                                        task, source_domain, data_type, 0)\n",
    "        target_train, target_train_label, target_test, target_test_label = load_dataset(\"../data/\", \n",
    "                                                                                        task, target_domain, data_type, p)\n",
    "\n",
    "\n",
    "        # get source reference prediction\n",
    "        model = load_model(\"../model/\", task, source_domain, model_type, 0, source_version)\n",
    "\n",
    "\n",
    "        # sample target supervised examples\n",
    "        target_train_index, sample_label = sample_validation_data(task, target_train_label, \n",
    "                                                                  ratio=1.0, number_examples=n_label)\n",
    "        target_sample = target_train[target_train_index]\n",
    "        target_sample_label = target_train_label[target_train_index]\n",
    "\n",
    "        \n",
    "        # Train the model with the best learning rate\n",
    "        train, valid, train_label, valid_label = train_test_split(target_sample, target_sample_label, test_size=0.25, \n",
    "                                                                  shuffle=True, random_state=0)\n",
    "        \n",
    "        for param in model.model.input_layer.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        model.fit(train, train_label[:, 1], \n",
    "                  train, \n",
    "                  valid, valid_label[:, 1], \n",
    "                  epoch=epoch, batch_size=batch_size, lr=0.001, beta=0, \n",
    "                  early_stop=False, verbose=False)\n",
    "        \n",
    "\n",
    "        pred = model.predict(target_test)\n",
    "\n",
    "        perf = performance_logloss(pred, target_test_label[:, 1])\n",
    "        model_log(\"../logs/logloss/\", task, source_domain, model_type, p, source_version, \n",
    "                 \"{}: {}\".format(version, perf))\n",
    "        print(\"Target Prediction logloss\", perf, flush=True)\n",
    "\n",
    "\n",
    "        perf = performance_pr_auc(pred, target_test_label[:, 1])\n",
    "        model_log(\"../logs/pr_auc/\", task, source_domain, model_type, p, source_version, \n",
    "                 \"{}: {}\".format(version, perf))\n",
    "        print(\"Target Prediction pr_auc\", perf, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
